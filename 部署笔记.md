[TOC]

---

# Ollama 部署

## Link

## Installation

### Setting environment variables on Linux

If Ollama is run as a systemd service, environment variables should be set using systemctl:
Edit the systemd service by calling systemctl edit ollama.service. This will open an editor.
For each environment variable, add a line Environment under section [Service]:

```Linux
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_MODELS=/mnt/d"
```

Save and exit.Reload systemd and restart Ollama:

```Linux
systemctl daemon-reload
systemctl restart ollama
```

### Setting environment variables on Windows

On windows, Ollama inherits your user and system environment variables.

1. First Quit Ollama by clicking on it in the task bar
2. Edit system environment variables from the control panel
3. Edit or create New variable(s) for your user account for **OLLAMA_HOST, OLLAMA_MODELS**, etc.
   Click OK/Apply to save
4. Run ollama from a new terminal window

## Usage



# OpenDevin 部署

# anythingLLM 部署

# Qanything 部署

# ComfyUI 部署

## Link

- [comfyanonymous/ComfyUI(github.com)](https://github.com/comfyanonymous/ComfyUI)

## Installation

### Windows

[Direct link to download](https://github.com/comfyanonymous/ComfyUI/releases/download/latest/ComfyUI_windows_portable_nvidia_cu121_or_cpu.7z), Simply click and download, extract with [7-Zip](https://7-zip.org/) and run. Make sure you put your Stable Diffusion checkpoints/models (the huge ckpt/safetensors files) in: ComfyUI\models\checkpoints，If you have trouble extracting it, right click the file -> properties -> unblock

## usage

- cd ComfyUI目录下，双击run_nvidia_gpu.bat
- How do I share models between another UI and ComfyUI? See the [Config file](https://github.com/comfyanonymous/ComfyUI/blob/master/extra_model_paths.yaml.example) to set the search paths for models. In the standalone windows build you can find this file in the ComfyUI directory. Rename this file to extra_model_paths.yaml and edit it with your favorite text editor.

## 课程

- [基础教程]([OUY-ComfyUI系列教程 - YouTube](https://www.youtube.com/playlist?list=PLK7sA3zrSa4s0tO8w2pdc7zPTcIAgS7ru))

- [应用变现]([YouTrack. AI Assistant (youtube.com)](https://www.youtube.com/watch?v=SyW6-POJANo&t=240s&ab_channel=牛猫AI分享))

# Dify 部署

# IOPaint 部署

## Link

1. [Install – IOPaint](https://www.iopaint.com/install)
2. [Sanster/IOPaint-github](https://github.com/Sanster/IOPaint)

## Installation

### Install pytorch

If you want to run model on GPU, it is necessary to install the GPU version of PyTorch. Otherwise, you can skip this step.

For NVIDIA GPU users

```
pip3 install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118
```

For AMD GPU users, only works on linux, as pytorch is not yet supported on Windows with ROCm.

```
pip3 install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/rocm5.6
```

### Install IOPaint

```
pip3 install iopaint
```

### Start IOPaint server

```
iopaint start --model=lama --device=cpu --port=8080
```

IOPaint is now running at [http://localhost:8080(opens in a new tab)](http://localhost:8080/), you can open it in your browser to start using it.

You can see all command line arguments using `iopaint start --help`, and you can see more models and features in the [models](https://www.iopaint.com/models) page.

## Usage

You can also use following to start a gradio page for configuration settings, the configuration will be saved in iopaint-config.json

```
iopaint start-web-config --config-file iopaint-config.json
```

and then use following to start the service.

```
iopaint start --config iopaint-config.json
```



# AdioCraft 部署

## Link

1. [facebookresearch/audiocraft(github.com)](https://github.com/facebookresearch/audiocraft/tree/main)

2. [Meta开源的AI音乐生成工具，可平替Suno，全网最详细本地部署使用教程，附Colab脚本(youtube.com)](https://www.youtube.com/watch?v=zObOSul8n6I&ab_channel=AI探索与发现)

   >AudioCraft加强版Magnet，文本到音频AI，可生成各种风格的音乐和声音，开源免费。本地安装详细教程，附Colab一键运行脚本。MusicGen最长可生成2分钟的音乐，Magnet可生成现场生活场景中的各种音效。Meta开源，完全免费。
   >
   >- 项目地址：https://github.com/facebookresearch/a...
   >  colab运行
   >  Magnet
   >  https://colab.research.google.com/dri...
   >  MusicGen
   >  https://colab.research.google.com/dri...
   >
   >- 一、本地安装
   >  cuda11.8
   >  python3.9.13  https://www.python.org/
   >  git工具  https://git-scm.com/
   >  ffmpeg  https://www.gyan.dev/ffmpeg/builds/
   >
   >- 二、命令窗口指令
   >  git clone https://github.com/facebookresearch/a...
   >  使用python3.9.13创建虚拟环境
   >  call venv\scripts\activate.bat
   >
   >  pip install -r requirements.txt
   >  pip uninstall torch torchvision torchaudio
   >  pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
   >  pip install xformers==0.0.22.post4 --index-url https://download.pytorch.org/whl/cu118
   >  pip install gradio==3.39.0   gradio_client==0.3.0
   >  python -m pip install -e .
   >
   >  
   >
   >  三、创建运行脚本
   >  music-run.bat
   >
   >  > call venv\scripts\activate.bat
   >  > echo start...
   >  > python -m demos.musicgen_app
   >  > pause
   >
   >  magnet-run.bat
   >
   >  > call venv\scripts\activate.bat
   >  > echo start...
   >  > python -m demos.magnet_app
   >  > pause

## Installation

### system env

1. Lenovo Y9000P

2. win11+NVIDIA 4070 Laotop

3. 注意的问题

   > - conda虚拟环境下安装pytorch要确定是GPU版本的，用conda install pytorch或
   >   pip3 install torch安装不一定是GPU版本
   > -  xformers需要降低版本，不然不识别cu118，可以将为0.0.22.post4

   

### activate conda env

```
conda creat -n AudioCraft_python python==3.9.13
conda activate AudioCraft_python
```

### install audiocraft

AudioCraft requires Python 3.9, PyTorch 2.1.0. To install AudioCraft, you can run the following:

:exclamation:Best to make sure you have torch installed first, in particular before installing xformers.

```
conda uninstall pytorch
pip uninstall torch torchvision torchaudio
# Don't run this if you already have PyTorch installed.
pip3 install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118
```

make sure you installed the torch + cuda + cudnn using:

```
python 
import torch #加载torch
print(torch.backends.cudnn.version()) #输出8200，代表着成功安装了cudnn v8.4.0
print(torch.__version__) #输出1.11.0，代表成功安装了pytorch 1.11.0
print(torch.version.cuda) #输出11.3，代表成功安装了cuda 11.3
torch.cuda.is_available() #ture代表成功
```

then following

```
# You might need the following before trying to install the packages
python -m pip install setuptools wheel
# Then proceed to one of the following
python -m pip install -U audiocraft  # stable release
#python -m pip install -U git+https://git@github.com/facebookresearch/audiocraft#egg=audiocraft  # bleeding edge
python -m pip install -e .  # or if you cloned the repo locally，and cd to the root folder (mandatory if you want to train).
```

降低xformers版本，不然一直识别cuda12以上

```
pip install xformers==0.0.22.post4 --index-url https://download.pytorch.org/whl/cu118
```

We also recommend having `ffmpeg` installed, either through your system or Anaconda:

```
sudo apt-get install ffmpeg
# Or if you are using Anaconda or Miniconda
conda install "ffmpeg<5" -c conda-forge
```

### change the model saving location

```bash
conda env config vars set AUDIOCRAFT_CACHE_DIR=D:\UbuntuFiles\audiocraft\models\huggingface\hub
conda env config vars set HUGGINGFACE_HUB_CACHE=D:\UbuntuFiles\audiocraft\models\huggingface\hub
conda env config vars set TORCH_HOME=D:\UbuntuFiles\audiocraft\models\torch
conda activate AudioCraft_python #reactivate conda env
conda env config vars list #check the env cofigure
```

## Usage

cd到本地代码根目录，打开cmd，激活conda环境，添加环境变量，产生旋律音乐运行下面的代码

```python
python -m demos.musicgen_app --share #MusicGen: A state-of-the-art controllable text-to-music model.
```

产生背景音乐运行下面的代码

```python
python -m demos.magnet_app --share #MAGNeT: A state-of-the-art non-autoregressive model for text-to-music and text-to-sound.
```













